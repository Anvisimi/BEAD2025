#BEAD 2025
Upon effective completion of the course, participants will be able to:
Understand the growth of big data and need for a scalable processing framework. Understand the fundamental characteristics, storage, analysis techniques and the relevant distributions
 Understand the distributed storage essentials, storage needs, and relevant architectural mechanism in processing large amounts of structured, semi-structured and unstructured data. 
Gain expertise with the fault-tolerant computing framework (E.g. Hadoop or Kubernetes) by setting up pseudo cluster nodes or cloud based nodes for processing big data. . 
Construct configurable and executable tasks using the In Memory Processing frameworks (E.g. Spark Core). Understand the nuances of writing functional programs and use the core libraries to manipulate the large corpse of unstructured data residing as Resilient Distributed Datasets. 
Organize, store and manipulate the collected data using processing libraries. For example, using special statistical operation and stream processing data tools (E.g. Spark Special Libraries). 
Understand various data processing, querying and persistence (E.g. Spark QL APIs) available for usage in RDDâ€™s context. Perform tasks such as filtering, selection and categorization. 
